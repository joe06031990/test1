// Defines the start of a declarative Jenkins pipeline for restoring Grafana dashboards.
// WARNING: This pipeline runs automatically and will overwrite dashboards without confirmation.
pipeline {
    // Specifies that the pipeline can run on any available Jenkins agent.
    agent any

    // This pipeline is now configured to run automatically on a schedule.
    triggers {
        // 'H * * * *' means the job will run approximately every hour.
        cron('H * * * *')
    }

    // Defines environment variables that will be available throughout the pipeline.
    environment {
        // Securely loads the Grafana API key from Jenkins credentials.
        GRAFANA_API_KEY = credentials('GRAFANA_API_KEY')
        // The URL of your Grafana instance.
        GRAFANA_URL = "https://jstest2025.grafana.net"
        // The name of the root directory where backups are stored in the Git repository.
        GRAFANA_BACKUP_DIR = "playground_nonprd"
    }

    // Contains all the main work stages of the pipeline.
    stages {
        // The first stage: responsible for checking out code from your Git repository.
        stage('Checkout Git Repository') {
            steps {
                // The 'checkout' step clones or updates the specified Git repository and branch.
                // Uses 'scm' to automatically checkout the branch that triggered this build
                checkout scm
            }
        }

        // This stage runs the restore script.
        stage('Run Grafana Restore') {
            steps {
                script {
                    // --- FIX: Python script for robust JSON parsing ---
                    // This Python script will be used to reliably find the folder ID from the Grafana API response.
                    def pythonParser = '''
import sys, json
try:
    folders = json.load(sys.stdin)
    title_to_find = sys.argv[1]
    for folder in folders:
        if folder.get("title") == title_to_find:
            print(folder.get("id"))
            sys.exit(0)
except Exception:
    sys.exit(1)
sys.exit(1)
'''
                    // Write the Python parser to a file in the workspace.
                    writeFile(file: 'folder_parser.py', text: pythonParser)

                    // Define the entire restore script as a Groovy multiline string.
                    def restoreScriptContent = '''
                        #!/bin/bash
                        # 'set -e' ensures the script will exit immediately if a command fails.
                        set -e
                        # 'set -x' prints each command to the log before it is executed, useful for debugging.
                        set -x

                        # Sanity checks to ensure required tools and variables are present.
                        if [ -z "${GRAFANA_URL}" ] || [ -z "${GRAFANA_API_KEY}" ] || [ -z "${GRAFANA_BACKUP_DIR}" ]; then
                            echo "Missing required environment variables (GRAFANA_URL, GRAFANA_API_KEY, GRAFANA_BACKUP_DIR)." >&2
                            exit 1
                        fi

                        if [ ! -d "${GRAFANA_BACKUP_DIR}" ]; then
                            echo "Error: Backup directory '${GRAFANA_BACKUP_DIR}' not found." >&2
                            exit 1
                        fi
                        
                        # --- Safety Check ---
                        # This script is specifically designed to restore the 'playground_nonprd' backup.
                        if [ "$(basename "${GRAFANA_BACKUP_DIR}")" != "playground_nonprd" ]; then
                            echo "Error: This script is configured to only restore the 'playground_nonprd' directory." >&2
                            echo "The target directory is '$(basename "${GRAFANA_BACKUP_DIR}")'. Aborting." >&2
                            exit 1
                        fi

                        echo "Starting Grafana restore from local directory '${GRAFANA_BACKUP_DIR}' to ${GRAFANA_URL}"

                        # A function to parse simple JSON values from strings.
                        extract_json_value() {
                            local json="$1"
                            local key="$2"
                            echo "$json" | awk -F"[,:{}\\\"]" -v key="$key" '{
                                for (i=1; i<=NF; i++) {
                                    if ($i == key) {
                                        # The value is the next non-empty field
                                        for (j=i+1; j<=NF; j++) {
                                            if ($j != "" && $j !~ /^[ \t]*$/) {
                                                print $j;
                                                exit;
                                            }
                                        }
                                    }
                                }
                            }'
                        }

                        # Use an associative array to keep track of folder IDs to avoid duplicate API calls
                        declare -A FOLDER_IDS

                        # Function to get or create a Grafana folder and return its ID
                        get_or_create_folder_id() {
                            local folder_title=$1
                            
                            if [ -n "${FOLDER_IDS[$folder_title]}" ]; then
                                echo "${FOLDER_IDS[$folder_title]}"
                                return
                            fi

                            # Search for the folder by title
                            local search_result
                            search_result=$(curl -s -H "Authorization: Bearer ${GRAFANA_API_KEY}" "${GRAFANA_URL}/api/search?type=dash-folder")
                            
                            # --- FIX: Use the Python script for reliable parsing ---
                            local folder_id
                            # Pipe the curl result into the python script. If it exits with an error (folder not found), '|| true' prevents 'set -e' from stopping the script.
                            folder_id=$(python folder_parser.py "${folder_title}" <<< "${search_result}") || true

                            if [ -n "$folder_id" ]; then
                                echo "Folder '${folder_title}' already exists with ID: ${folder_id}" >&2
                            else
                                echo "Folder '${folder_title}' not found. Creating it..." >&2
                                local create_payload="{\\"title\\": \\"${folder_title}\\"}"
                                
                                local create_result
                                create_result=$(curl -s -X POST -H "Authorization: Bearer ${GRAFANA_API_KEY}" -H "Content-Type: application/json" --data "$create_payload" "${GRAFANA_URL}/api/folders")
                                
                                folder_id=$(extract_json_value "$create_result" "id")
                                
                                if [ -z "$folder_id" ]; then
                                    echo "Error: Failed to create folder '${folder_title}'. Response: ${create_result}" >&2
                                    exit 1
                                fi
                                echo "Successfully created folder '${folder_title}' with ID: ${folder_id}" >&2
                            fi
                            
                            FOLDER_IDS["$folder_title"]=$folder_id
                            echo "$folder_id"
                        }

                        # PASS 1: Pre-create all necessary folders
                        echo "--- Pass 1: Ensuring all Grafana folders exist ---"
                        # Create a unique list of all folder names required by the backup.
                        find "${GRAFANA_BACKUP_DIR}" -type f -name "*.json" | while read -r dashboard_path; do
                            path_in_backup="${dashboard_path#${GRAFANA_BACKUP_DIR}/}"
                            if [[ "$path_in_backup" == *"/"* ]]; then
                                subfolder_name="${path_in_backup%%/*}"
                                echo "playground_${subfolder_name}"
                            else
                                echo "playground"
                            fi
                        done | sort -u | while read -r folder_name; do
                            echo "Checking/creating folder: ${folder_name}"
                            get_or_create_folder_id "${folder_name}" > /dev/null
                        done
                        echo "--- Folder check complete ---"

                        # PASS 2: Restore all dashboards
                        echo "--- Pass 2: Restoring all dashboards ---"
                        find "${GRAFANA_BACKUP_DIR}" -type f -name "*.json" | while read -r dashboard_path; do
                            echo "--- Processing dashboard: ${dashboard_path} ---"
                            
                            # This logic more reliably determines the correct target folder.
                            TARGET_FOLDER_ID=""
                            path_in_backup="${dashboard_path#${GRAFANA_BACKUP_DIR}/}"

                            if [[ "$path_in_backup" == *"/"* ]]; then
                                subfolder_name="${path_in_backup%%/*}"
                                folder_name="playground_${subfolder_name}"
                                TARGET_FOLDER_ID=$(get_or_create_folder_id "${folder_name}")
                            else
                                TARGET_FOLDER_ID=$(get_or_create_folder_id "playground")
                            fi
                            
                            if [ -z "$TARGET_FOLDER_ID" ]; then
                                echo "Could not determine Folder ID for '${dashboard_path}'. Skipping dashboard."
                                continue
                            fi
                            
                            # Read the full JSON content from the backup file
                            full_backup_json=$(cat "${dashboard_path}")

                            # Extract the main dashboard object and remove its "id" field.
                            dashboard_object=$(echo "$full_backup_json" | sed 's/.*,"dashboard"://' | sed 's/}$//' | sed 's/"id":[0-9]*,//')

                            if [ -z "$dashboard_object" ]; then
                                echo "Error: Could not extract dashboard object from '${dashboard_path}'. Skipping."
                                continue
                            fi
                            
                            # Construct the final payload by adding the folderId and overwrite keys.
                            restore_payload=$(printf '{"dashboard": %s, "folderId": %s, "overwrite": true}' "$dashboard_object" "$TARGET_FOLDER_ID")

                            restore_result=$(curl -s -X POST -H "Authorization: Bearer ${GRAFANA_API_KEY}" -H "Content-Type: application/json" --data-raw "${restore_payload}" "${GRAFANA_URL}/api/dashboards/db")

                            status=$(extract_json_value "$restore_result" "status")
                            if [ "$status" == "success" ]; then
                                echo "Successfully restored dashboard from '${dashboard_path}'"
                            else
                                echo "Error restoring dashboard from '${dashboard_path}'. Response: ${restore_result}"
                            fi
                        done

                        echo "--- Grafana restore process complete. ---"
                    '''
                    
                    // Write the script content to a file in the workspace
                    writeFile(file: 'run_grafana_restore.sh', text: restoreScriptContent)
                    // Make the file executable
                    sh 'chmod +x run_grafana_restore.sh'
                    // Execute the script explicitly with bash to ensure compatibility
                    sh 'bash ./run_grafana_restore.sh'
                }
            }
        }
    }

    // The 'post' section defines actions that run at the end of the pipeline.
    post {
        // 'always' means this action will run regardless of whether the pipeline succeeded or failed.
        always {
            // Clean up the workspace
            deleteDir()
        }
    }
}
